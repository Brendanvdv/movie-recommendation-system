# Movie Recommendation System Using Hybrid Similarity

**Course:** 02807 Computational Tools for Data Science  
**Institution:** Technical University of Denmark (DTU)  
**Semester:** Autumn 2024

## Project Summary

This project implements a **hybrid movie recommendation system** that combines multiple similarity dimensions to find movies similar to a given query. Using the Rotten Tomatoes dataset, we demonstrate:

1. **Course Topic 1 - Similar Items:** We compute pairwise similarity across movies using six distinct feature types, combined through weighted averaging.

2. **Course Topic 2 - Clustering:** K-Means clustering is applied to group movies by genre characteristics, with evaluation using Davies-Bouldin index and silhouette scores.

3. **Outside Topic - Topic Modeling (LDA):** We use Latent Dirichlet Allocation to discover latent topics from critic reviews, enabling automatic genre label generation based on review content rather than predefined categories.

The system produces recommendations by computing a hybrid similarity score:

$$
S_{hybrid} = \alpha \cdot S_{info} + \beta \cdot S_{rating} + \gamma \cdot S_{genre} + \delta \cdot S_{year} + \epsilon \cdot S_{style} + \zeta \cdot S_{type}
$$

---

## Data Requirements
Place the following files in the `datasets/` folder:

- `rotten_tomatoes_movies.csv`
- `rotten_tomatoes_critic_reviews.csv`

**Dataset Source:**  
[Rotten Tomatoes Movies and Critic Reviews Dataset on Kaggle](https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset/data?select=rotten_tomatoes_movies.csv)

---

## Dependencies
All required Python packages are listed in `requirements.txt`. Install them using:

```bash
pip install -r requirements.txt
```
The required packages are also stated at the start of the notebooks.

---

## How to Run

### Step 1: Build the Dataset
Run `build_dataset.ipynb` to create the final dataset from the raw Rotten Tomatoes files.

**Dataset Size Configuration:**

The notebook includes an option to create a smaller dataset for faster processing:

```python
CREATE_SAMPLE = True  # Set to False for full dataset
SAMPLE_SIZE = 2000     # Number of movies to include
```

- **Sample mode** (`CREATE_SAMPLE = True`): Creates dataset with 2,000 movies
  - Processing time: ~5-10 minutes
  - Includes "Aliens", "Toy Story", and "The Godfather" for demonstrations
  - Recommended for development and testing

- **Full mode** (`CREATE_SAMPLE = False`): Creates dataset with all ~15,500 movies
  - Processing time: ~45 minutes
  - Recommended for final submission or comprehensive analysis

The sampling is done at the dataset creation stage, so the rest of the pipeline requires no modifications.

### Step 2: Run the Analysis
Run `final_demonstration.ipynb` to see the complete recommendation system with:
- Similarity-based recommendations
- LDA-generated genre labels
- K-Means clustering results
- Three demonstration outputs (Aliens, Toy Story, The Godfather)

### Additional Notebooks
The following notebooks can be run to explore individual components:
- `similarity_system.ipynb` - Similarity computation details
- `movie_genre_clustering_analysis.ipynb` - Clustering analysis
- `final_topic_modelling.ipynb` - LDA topic modeling
- `tomatoes.ipynb` - Comparative analysis

---

## Cache Files

The system automatically generates cache files in the `cache/` directory to avoid recomputation:

- `vectorized_movie_data.pkl` - Movie embeddings and features
- `similarity_matrices.pkl` - Six individual similarity matrices
- `hybrid_similarity.pkl` - Combined hybrid similarity matrix
- `lda_model.pkl` - Trained LDA topic model
- `lda_dictionary.pkl` - LDA dictionary

These cache files make subsequent runs much faster (~10-20 seconds to load instead of minutes to compute).

---

## Project Structure

```
.
├── datasets/
│   ├── rotten_tomatoes_movies.csv (from Kaggle)
│   ├── rotten_tomatoes_critic_reviews.csv (from Kaggle)
│   └── final_dataset.csv (generated by build_dataset.ipynb)
├── cache/ (generated automatically)
│   ├── vectorized_movie_data.pkl
│   ├── similarity_matrices.pkl
│   ├── hybrid_similarity.pkl
│   ├── lda_model.pkl
│   └── lda_dictionary.pkl
├── build_dataset.ipynb
├── final_demonstration.ipynb
├── similarity_system.ipynb
├── movie_genre_clustering_analysis.ipynb
├── final_topic_modelling.ipynb
├── requirements.txt
└── README.md
```

---

## Notes

- The sampling approach (if used) creates a representative subset of movies while ensuring demonstration movies are included
- All notebooks work identically regardless of dataset size
- Cache files significantly speed up subsequent runs
- The system demonstrates all three required course topics with proper evaluation metrics
