{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System Using Hybrid Similarity\n",
    "\n",
    "**Course:** 02807 Computational Tools for Data Science  \n",
    "**Institution:** Technical University of Denmark (DTU)  \n",
    "**Semester:** Autumn 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Project Summary\n",
    "\n",
    "This project implements a hybrid movie recommendation system that combines multiple similarity dimensions. Using the Rotten Tomatoes dataset, we demonstrate:\n",
    "\n",
    "1. **Course Topic 1 - Similar Items:** We compute pairwise similarity across movies using six distinct feature types, combined through weighted averaging.\n",
    "\n",
    "2. **Course Topic 2 - Clustering:** K-Means clustering groups movies by genre characteristics, with evaluation using Davies-Bouldin index and silhouette scores.\n",
    "\n",
    "3. **Outside Topic - Topic Modeling (LDA):** We use Latent Dirichlet Allocation to discover latent topics from critic reviews, enabling automatic genre label generation based on review content.\n",
    "\n",
    "The system produces recommendations by computing a hybrid similarity score:\n",
    "\n",
    "$$S_{hybrid} = \\alpha \\cdot S_{info} + \\beta \\cdot S_{rating} + \\gamma \\cdot S_{genre} + \\delta \\cdot S_{year} + \\epsilon \\cdot S_{style} + \\zeta \\cdot S_{type}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Dependencies](#1-setup-and-dependencies)\n",
    "2. [Data Loading and Preprocessing](#2-data-loading-and-preprocessing)\n",
    "3. [Feature Engineering and Vectorization](#3-feature-engineering-and-vectorization)\n",
    "4. [Topic Modeling - LDA (Outside Topic)](#4-topic-modeling---lda-outside-topic)\n",
    "5. [Similarity Matrix Construction](#5-similarity-matrix-construction)\n",
    "6. [Hybrid Scoring System](#6-hybrid-scoring-system)\n",
    "7. [Clustering Analysis (Course Topic 2)](#7-clustering-analysis-course-topic-2)\n",
    "8. [Final Recommendation System](#8-final-recommendation-system)\n",
    "9. [Results and Evaluation](#9-results-and-evaluation)\n",
    "10. [Conclusion](#10-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup and Dependencies\n",
    "\n",
    "This section imports all required libraries for the project. Key dependencies include:\n",
    "- **sentence-transformers** for creating text embeddings\n",
    "- **scikit-learn** for similarity computation, clustering, and evaluation metrics\n",
    "- **gensim** for LDA topic modeling\n",
    "- **nltk** for text preprocessing (stopwords, lemmatization)\n",
    "\n",
    "The global configuration defines parameters used throughout the project, including genre categories, content rating types, minimum review threshold, and number of LDA topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if running for the first time)\n",
    "# !pip install sentence-transformers pandas numpy scikit-learn matplotlib seaborn gensim nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Sentence Transformers (for embeddings)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Topic Modeling (Outside Topic)\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "%matplotlib inline\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking 17 genres and 5 content ratings\n",
      "LDA will discover 15 latent topics\n"
     ]
    }
   ],
   "source": [
    "# All possible genres in the dataset\n",
    "ALL_GENRES = [\n",
    "    'science fiction & fantasy', 'drama', 'western', 'comedy', 'classics',\n",
    "    'action & adventure', 'kids & family', 'musical & performing arts',\n",
    "    'documentary', 'art house & international', 'horror', 'sports & fitness',\n",
    "    'faith & spirituality', 'mystery & suspense', 'animation', 'special interest', 'romance'\n",
    "]\n",
    "\n",
    "ALL_AGE_RATINGS = ['pg', 'r', 'g', 'pg-13', 'nc17']\n",
    "MIN_REVIEWS = 5\n",
    "NUM_TOPICS = 15\n",
    "\n",
    "print(f\"Tracking {len(ALL_GENRES)} genres and {len(ALL_AGE_RATINGS)} content ratings\")\n",
    "print(f\"LDA will discover {NUM_TOPICS} latent topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "This section loads the Rotten Tomatoes dataset and groups critic reviews by movie. Each movie must have at least 5 reviews to be included in the analysis. The grouped data structure contains movie metadata (title, year, genres, content rating) along with all associated critic reviews and review types (fresh/rotten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset() -> pd.DataFrame:\n",
    "    \"\"\"Load the final dataset\"\"\"\n",
    "    dataset = '../datasets/final_dataset.csv'\n",
    "    final_dataset = pd.read_csv(dataset)\n",
    "    return final_dataset\n",
    "\n",
    "def group_movies(final_dataset, min_reviews=MIN_REVIEWS):\n",
    "    \"\"\"Group reviews by movie\"\"\"\n",
    "    grouped = final_dataset.groupby('rotten_tomatoes_link')\n",
    "    movie_data = []\n",
    "\n",
    "    for movie_id, group in grouped:\n",
    "        reviews = group['review_content'].tolist()\n",
    "        critic_names = group['critic_name'].to_list()\n",
    "        review_types = group['review_type'].to_list()\n",
    "        first_row = group.iloc[0]\n",
    "\n",
    "        movie_data.append({\n",
    "            'movie_id': movie_id,\n",
    "            'movie_title': first_row['movie_title'],\n",
    "            'content_rating': first_row['content_rating'],\n",
    "            'genres': first_row['genres'],\n",
    "            'year': int(first_row['original_release_date']) if str(first_row['original_release_date']).isdigit() else 0,\n",
    "            'movie_info': first_row['movie_info'],\n",
    "            'reviews': reviews,\n",
    "            'critic_names': critic_names,\n",
    "            'review_types': review_types,\n",
    "            'combined_review_text': ' '.join(reviews)\n",
    "        })\n",
    "    \n",
    "    movie_data_filtered = [m for m in movie_data if len(m['reviews']) >= min_reviews]\n",
    "    print(f\"Loaded {len(movie_data_filtered)} movies with >= {min_reviews} reviews\")\n",
    "    return movie_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 48 movies with >= 5 reviews\n"
     ]
    }
   ],
   "source": [
    "# Load and process dataset\n",
    "final_dataset = get_dataset()\n",
    "movie_data = group_movies(final_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Feature Engineering and Vectorization\n",
    "\n",
    "This section transforms movie data into numerical representations that can be compared mathematically. We use the sentence-transformers library to create 384-dimensional embeddings for movie descriptions and critic reviews. Additional features include binary encodings for genres and content ratings, normalized release years, and fresh/rotten review patterns. The vectorization process takes 10-20 minutes for the full dataset, so results are cached for faster subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(movie_data: list, model) -> list[dict]:\n",
    "    \"\"\"Create embeddings for content and review style\"\"\"\n",
    "    \n",
    "    def encode_genres(movie_genres: list, all_genres: list):\n",
    "        return [1 if genre in movie_genres else 0 for genre in all_genres]\n",
    "    \n",
    "    def encode_content_rating(content_rating, all_content_ratings):\n",
    "        return [1 if cr == content_rating else 0 for cr in all_content_ratings]\n",
    "    \n",
    "    def encode_review_type(review_types):\n",
    "        return [1 if rt == \"fresh\" else 0 for rt in review_types]\n",
    "    \n",
    "    years = [movie['year'] for movie in movie_data if movie['year'] > 0]\n",
    "    min_year = min(years)\n",
    "    max_year = max(years)\n",
    "\n",
    "    total_movies = len(movie_data)\n",
    "\n",
    "    for i, movie in enumerate(movie_data, start=1):\n",
    "        if i % 500 == 0 or i == total_movies:\n",
    "            print(f\"Processing movie {i}/{total_movies} ({i/total_movies*100:.1f}%)\")\n",
    "\n",
    "        movie['movie_info_embeddings'] = model.encode(movie['movie_info'])\n",
    "        movie['content_rating_norm'] = encode_content_rating(movie['content_rating'], ALL_AGE_RATINGS)\n",
    "        movie['genre_vector'] = encode_genres(movie['genres'], ALL_GENRES)\n",
    "        movie['year_norm'] = (movie['year'] - min_year) / (max_year - min_year)\n",
    "        \n",
    "        review_embeddings = model.encode(movie['reviews'])\n",
    "        movie['avg_review_embeddings'] = review_embeddings.mean(axis=0)\n",
    "        movie['review_types_norm'] = encode_review_type(movie['review_types'])\n",
    "    \n",
    "    return movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ../cache/vectorized_movie_data.pkl...\n",
      "Loaded 48 movies\n"
     ]
    }
   ],
   "source": [
    "# Load or create vectorized data\n",
    "VECTORIZED_PATH = '../cache/vectorized_movie_data.pkl'\n",
    "\n",
    "if os.path.exists(VECTORIZED_PATH):\n",
    "    print(f\"Loading from {VECTORIZED_PATH}...\")\n",
    "    with open(VECTORIZED_PATH, 'rb') as f:\n",
    "        vectorized_data = pickle.load(f)\n",
    "    \n",
    "    # Ensure combined_review_text exists (for backward compatibility)\n",
    "    for movie in vectorized_data:\n",
    "        if 'combined_review_text' not in movie:\n",
    "            movie['combined_review_text'] = ' '.join(movie['reviews'])\n",
    "else:\n",
    "    print(\"Vectorizing data...\")\n",
    "    st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    vectorized_data = vectorize(movie_data, st_model)\n",
    "    with open(VECTORIZED_PATH, 'wb') as f:\n",
    "        pickle.dump(vectorized_data, f)\n",
    "        \n",
    "print(f\"Loaded {len(vectorized_data)} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Topic Modeling - LDA (Outside Topic)\n",
    "\n",
    "### 4.1 Introduction to LDA\n",
    "\n",
    "**Latent Dirichlet Allocation (LDA)** is a generative probabilistic model that discovers latent topics in a collection of documents. Each document is represented as a mixture of topics, and each topic is a distribution over words.\n",
    "\n",
    "**Why LDA for movie recommendations:**\n",
    "- Discovers hidden thematic patterns in critic reviews\n",
    "- Generates interpretable genre-like labels automatically\n",
    "- Captures nuanced movie characteristics beyond predefined genre categories\n",
    "\n",
    "**Implementation details:**\n",
    "- Text preprocessing removes stopwords and applies lemmatization\n",
    "- We train an LDA model with 15 topics on the combined movie descriptions and critic reviews\n",
    "- Each movie receives a topic distribution vector, indicating the probability of belonging to each discovered topic\n",
    "- Topic labels are manually mapped to interpretable genre-like categories based on the most prominent words in each topic\n",
    "- The top 3 topics (with >5% probability) become the movie's generated genre labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update({\"movie\", \"film\", \"films\", \"story\", \"character\", \"characters\"})\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \" \", str(text))\n",
    "    return text.lower()\n",
    "\n",
    "def preprocess_for_lda(text):\n",
    "    tokens = simple_preprocess(text, deacc=True)\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words and len(t) > 2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained LDA model...\n"
     ]
    }
   ],
   "source": [
    "# Build or load LDA model\n",
    "LDA_MODEL_PATH = '../cache/lda_model.pkl'\n",
    "LDA_DICT_PATH = '../cache/lda_dictionary.pkl'\n",
    "\n",
    "if os.path.exists(LDA_MODEL_PATH) and os.path.exists(LDA_DICT_PATH):\n",
    "    print(\"Loading pre-trained LDA model...\")\n",
    "    with open(LDA_MODEL_PATH, 'rb') as f:\n",
    "        lda_model = pickle.load(f)\n",
    "    with open(LDA_DICT_PATH, 'rb') as f:\n",
    "        dictionary = pickle.load(f)\n",
    "else:\n",
    "    print(\"Training LDA model...\")\n",
    "    texts_for_lda = []\n",
    "    for movie in vectorized_data:\n",
    "        combined = movie['movie_title'] + ' ' + movie['movie_info'] + ' ' + movie['combined_review_text']\n",
    "        tokens = preprocess_for_lda(clean_text(combined))\n",
    "        texts_for_lda.append(tokens)\n",
    "        movie['tokens'] = tokens\n",
    "    \n",
    "    dictionary = Dictionary(texts_for_lda)\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in texts_for_lda]\n",
    "    \n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=NUM_TOPICS,\n",
    "                         random_state=42, passes=10, alpha='auto', eta='auto')\n",
    "    \n",
    "    with open(LDA_MODEL_PATH, 'wb') as f:\n",
    "        pickle.dump(lda_model, f)\n",
    "    with open(LDA_DICT_PATH, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "    print(\"LDA model trained and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered Topics:\n",
      "================================================================================\n",
      "Topic  0: way, enough, keep, genre, kind, something, another, thing\n",
      "Topic  1: original, real, better, less, best, also, right, despite\n",
      "Topic  2: dialogue, action, idea, genre, filmmaker, human, despite, enough\n",
      "Topic  3: full, actor, great, never, feel, man, scene, could\n",
      "Topic  4: full, feel, drama, great, love, also, man, enough\n",
      "Topic  5: action, thriller, genre, original, movie, great, fun, never\n",
      "Topic  6: american, great, every, movie, see, less, year, best\n",
      "Topic  7: sense, rather, year, great, tale, lack, movie, old\n",
      "Topic  8: comedy, love, give, way, turn, see, best, get\n",
      "Topic  9: original, thing, better, best, get, feel, bad, year\n",
      "Topic 10: full, man, best, scene, drama, feel, great, year\n",
      "Topic 11: show, fun, old, kind, original, try, could, watching\n",
      "Topic 12: thriller, genre, best, way, drama, get, better, know\n",
      "Topic 13: bad, comedy, audience, hard, thing, way, minute, nothing\n",
      "Topic 14: people, see, experience, get, way, enough, filmmaker, know\n"
     ]
    }
   ],
   "source": [
    "# Display discovered topics\n",
    "print(\"Discovered Topics:\")\n",
    "print(\"=\" * 80)\n",
    "for idx, topic in lda_model.print_topics(num_topics=NUM_TOPICS, num_words=8):\n",
    "    words = re.findall(r'\"([^\"]+)\"', topic)\n",
    "    print(f\"Topic {idx:2d}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic label mapping - customize based on your discovered topics\n",
    "TOPIC_LABELS = {\n",
    "    0: \"Action/Thriller\", 1: \"Drama/Character\", 2: \"Comedy/Light\", 3: \"Horror/Suspense\",\n",
    "    4: \"Family/Animation\", 5: \"Documentary\", 6: \"Sci-Fi/Fantasy\", 7: \"Romance\",\n",
    "    8: \"Crime/Mystery\", 9: \"War/Historical\", 10: \"Musical/Arts\", 11: \"Sports\",\n",
    "    12: \"International\", 13: \"Adventure/Epic\", 14: \"Classic/Timeless\"\n",
    "}\n",
    "\n",
    "def get_topic_vector(tokens, dictionary, lda_model, num_topics):\n",
    "    bow = dictionary.doc2bow(tokens)\n",
    "    topic_dist = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    vec = np.zeros(num_topics)\n",
    "    for topic_id, prob in topic_dist:\n",
    "        vec[topic_id] = prob\n",
    "    return vec\n",
    "\n",
    "def get_generated_genres(topic_vector, top_n=3):\n",
    "    top_indices = np.argsort(topic_vector)[::-1][:top_n]\n",
    "    genres = []\n",
    "    for idx in top_indices:\n",
    "        if topic_vector[idx] > 0.05:\n",
    "            label = TOPIC_LABELS.get(idx, f\"Topic_{idx}\")\n",
    "            pct = int(topic_vector[idx] * 100)\n",
    "            genres.append(f\"{label} ({pct}%)\")\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing topic vectors...\n",
      "\n",
      "Example: aliens\n",
      "  Generated genres: ['Documentary (92%)', 'International (7%)']\n"
     ]
    }
   ],
   "source": [
    "# Compute topic vectors for all movies\n",
    "print(\"Computing topic vectors...\")\n",
    "for movie in vectorized_data:\n",
    "    if 'tokens' not in movie:\n",
    "        combined = movie['movie_title'] + ' ' + movie['movie_info'] + ' ' + movie['combined_review_text']\n",
    "        movie['tokens'] = preprocess_for_lda(clean_text(combined))\n",
    "    movie['topic_vector'] = get_topic_vector(movie['tokens'], dictionary, lda_model, NUM_TOPICS)\n",
    "    movie['generated_genres'] = get_generated_genres(movie['topic_vector'])\n",
    "\n",
    "print(f\"\\nExample: {vectorized_data[0]['movie_title']}\")\n",
    "print(f\"  Generated genres: {vectorized_data[0]['generated_genres']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Similarity Matrix Construction\n",
    "\n",
    "This section builds six separate similarity matrices, each capturing a different dimension of movie similarity:\n",
    "\n",
    "1. **Info Similarity** - Semantic similarity of movie descriptions using cosine similarity on embeddings\n",
    "2. **Content Rating Similarity** - Matches based on age appropriateness (G, PG, PG-13, R, NC-17)\n",
    "3. **Genre Similarity** - Overlap in genre categories (drama, comedy, action, etc.)\n",
    "4. **Year Similarity** - Temporal proximity of release dates\n",
    "5. **Review Style Similarity** - How critics write about movies (embeddings of review text)\n",
    "6. **Review Type Similarity** - Correlation of fresh/rotten patterns across critics\n",
    "\n",
    "Each matrix is NÃ—N where N is the number of movies, with values ranging from 0 (dissimilar) to 1 (identical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_info_sim(vectorized_movie_data) -> np.ndarray:\n",
    "    info_vectors = np.vstack([movie['movie_info_embeddings'] for movie in vectorized_movie_data])\n",
    "    info_sim = cosine_similarity(info_vectors).astype('float32')\n",
    "    print(f\"Info similarity matrix: {info_sim.shape}\")\n",
    "    return info_sim\n",
    "\n",
    "def build_content_rating_sim(vectorized_movie_data) -> np.ndarray:\n",
    "    content_rating_vectors = np.vstack([movie['content_rating_norm'] for movie in vectorized_movie_data])\n",
    "    content_rating_sim = cosine_similarity(content_rating_vectors).astype('float32')\n",
    "    print(f\"Content rating similarity matrix: {content_rating_sim.shape}\")\n",
    "    return content_rating_sim\n",
    "\n",
    "def build_genre_sim(vectorized_movie_data) -> np.ndarray:\n",
    "    genre_vectors = np.vstack([movie['genre_vector'] for movie in vectorized_movie_data])\n",
    "    genre_sim = cosine_similarity(genre_vectors).astype('float32')\n",
    "    print(f\"Genre similarity matrix: {genre_sim.shape}\")\n",
    "    return genre_sim\n",
    "\n",
    "def build_year_sim(vectorized_movie_data) -> np.ndarray:\n",
    "    year_vectors = np.vstack([movie['year_norm'] for movie in vectorized_movie_data])\n",
    "    year_sim = cosine_similarity(year_vectors).astype('float32')\n",
    "    print(f\"Year similarity matrix: {year_sim.shape}\")\n",
    "    return year_sim\n",
    "\n",
    "def build_review_style_sim(vectorized_movie_data) -> np.ndarray:\n",
    "    review_embeddings = np.vstack([movie['avg_review_embeddings'] for movie in vectorized_movie_data])\n",
    "    review_sim = cosine_similarity(review_embeddings).astype('float32')\n",
    "    print(f\"Review similarity matrix: {review_sim.shape}\")\n",
    "    return review_sim\n",
    "\n",
    "def build_review_type_sim(vectorized_movie_data) -> np.ndarray:\n",
    "    all_critics = set()\n",
    "    for movie in vectorized_movie_data:\n",
    "        all_critics.update(movie['critic_names'])\n",
    "    all_critics = sorted(all_critics)\n",
    "\n",
    "    all_movies = [movie['movie_title'] for movie in vectorized_movie_data]\n",
    "    matrix = pd.DataFrame(np.nan, index=all_movies, columns=all_critics)\n",
    "\n",
    "    for movie in vectorized_movie_data:\n",
    "        mit = movie['movie_title']\n",
    "        for critic, review_type in zip(movie['critic_names'], movie['review_types_norm']):\n",
    "            matrix.loc[mit, critic] = review_type\n",
    "\n",
    "    type_sim = matrix.T.corr(method='pearson')\n",
    "    type_sim = (type_sim + 1) / 2\n",
    "    type_sim_array = type_sim.values\n",
    "    type_sim = np.nan_to_num(type_sim_array, nan=0.5)\n",
    "\n",
    "    print(f\"Type similarity matrix: {type_sim.shape}\")\n",
    "    return type_sim\n",
    "\n",
    "def build_sim_matrices(vectorized_data):\n",
    "    info_sim = build_info_sim(vectorized_data)\n",
    "    content_rating_sim = build_content_rating_sim(vectorized_data)\n",
    "    genre_sim = build_genre_sim(vectorized_data)\n",
    "    year_sim = build_year_sim(vectorized_data)\n",
    "    style_sim = build_review_style_sim(vectorized_data)\n",
    "    type_sim = build_review_type_sim(vectorized_data)\n",
    "    return info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading similarity matrices...\n",
      "Matrices ready\n"
     ]
    }
   ],
   "source": [
    "SIMILARITY_PATH = '../cache/similarity_matrices.pkl'\n",
    "\n",
    "if os.path.exists(SIMILARITY_PATH):\n",
    "    print(f\"Loading similarity matrices...\")\n",
    "    with open(SIMILARITY_PATH, 'rb') as f:\n",
    "        matrices = pickle.load(f)\n",
    "    info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim = (\n",
    "        matrices['info'], matrices['content_rating'], matrices['genre'],\n",
    "        matrices['year'], matrices['style'], matrices['type']\n",
    "    )\n",
    "else:\n",
    "    print(\"Computing similarity matrices...\")\n",
    "    info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim = build_sim_matrices(vectorized_data)\n",
    "    with open(SIMILARITY_PATH, 'wb') as f:\n",
    "        pickle.dump({'info': info_sim, 'content_rating': content_rating_sim, 'genre': genre_sim,\n",
    "                     'year': year_sim, 'style': style_sim, 'type': type_sim}, f)\n",
    "print(\"Matrices ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Hybrid Scoring System\n",
    "\n",
    "The hybrid scoring system combines all six similarity matrices using weighted averaging. Each component receives a weight (α , β , γ , δ , ε, ζ) that determines its contribution to the final similarity score. The current configuration uses equal weights for the main features:\n",
    "\n",
    "- α  = 0.2 (Info embeddings - semantic content)\n",
    "- β  = 0.2 (Content rating)\n",
    "- γ  = 0.2 (Genre)\n",
    "- δ  = 0.2 (Release year)\n",
    "- ε = 0.1 (Review style)\n",
    "- ζ = 0.1 (Review type patterns)\n",
    "\n",
    "This balanced approach gives equal importance to the four primary dimensions (info, rating, genre, year) while treating the review-based features as secondary signals. These weights can be adjusted to emphasize different aspects of similarity depending on the use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid similarity matrix created for 48 movies\n"
     ]
    }
   ],
   "source": [
    "def hybrid_score(info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim,\n",
    "                 alpha=0.2, beta=0.2, gamma=0.2, delta=0.2, epsilon=0.1, zeta=0.1):\n",
    "    return (alpha*info_sim + beta*content_rating_sim + gamma*genre_sim + \n",
    "            delta*year_sim + epsilon*style_sim + zeta*type_sim)\n",
    "\n",
    "hybrid_sim = hybrid_score(info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim)\n",
    "title_to_idx = {m['movie_title']: i for i, m in enumerate(vectorized_data)}\n",
    "print(f\"Hybrid similarity matrix created for {len(title_to_idx)} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Clustering Analysis (Course Topic 2)\n",
    "\n",
    "K-Means clustering groups movies based on their genre characteristics. We use standardized genre vectors as input features and evaluate different values of k (number of clusters) using two metrics:\n",
    "\n",
    "- **Silhouette Score** - Measures how well-separated clusters are (higher is better)\n",
    "- **Davies-Bouldin Index** - Measures cluster compactness and separation (lower is better)\n",
    "\n",
    "The optimal k is selected based on these metrics, and each movie is assigned to a cluster. Movies in the same cluster share similar genre profiles, providing an alternative grouping strategy to complement the similarity-based recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k by Silhouette: 3\n",
      "Optimal k by Davies-Bouldin: 15\n"
     ]
    }
   ],
   "source": [
    "genre_matrix = np.vstack([m['genre_vector'] for m in vectorized_data])\n",
    "scaler = StandardScaler()\n",
    "genre_scaled = scaler.fit_transform(genre_matrix)\n",
    "\n",
    "# Find optimal k\n",
    "k_range = range(2, 16)\n",
    "silhouettes = [silhouette_score(genre_scaled, KMeans(n_clusters=k, random_state=42, n_init=10).fit_predict(genre_scaled)) for k in k_range]\n",
    "db_scores = [davies_bouldin_score(genre_scaled, KMeans(n_clusters=k, random_state=42, n_init=10).fit_predict(genre_scaled)) for k in k_range]\n",
    "\n",
    "print(f\"Optimal k by Silhouette: {list(k_range)[np.argmax(silhouettes)]}\")\n",
    "print(f\"Optimal k by Davies-Bouldin: {list(k_range)[np.argmin(db_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster distribution:\n",
      "  Cluster 0: 23 movies\n",
      "  Cluster 1: 1 movies\n",
      "  Cluster 2: 7 movies\n",
      "  Cluster 3: 3 movies\n",
      "  Cluster 4: 2 movies\n",
      "  Cluster 5: 2 movies\n",
      "  Cluster 6: 6 movies\n",
      "  Cluster 7: 4 movies\n"
     ]
    }
   ],
   "source": [
    "# Final clustering\n",
    "OPTIMAL_K = 8\n",
    "kmeans = KMeans(n_clusters=OPTIMAL_K, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(genre_scaled)\n",
    "\n",
    "for i, m in enumerate(vectorized_data):\n",
    "    m['cluster'] = cluster_labels[i]\n",
    "\n",
    "print(f\"\\nCluster distribution:\")\n",
    "for c, cnt in zip(*np.unique(cluster_labels, return_counts=True)):\n",
    "    print(f\"  Cluster {c}: {cnt} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Final Recommendation System\n",
    "\n",
    "The final recommendation system integrates all three components:\n",
    "\n",
    "1. **Similar Items** - Returns the top k most similar movies based on hybrid similarity scores\n",
    "2. **Generated Genres** - Displays LDA-discovered topic labels for each recommendation\n",
    "3. **Cluster Members** - Shows other movies from the same K-Means cluster\n",
    "\n",
    "For each query movie, the system displays:\n",
    "- Original metadata (year, content rating, genres)\n",
    "- LDA-generated genre labels based on review content\n",
    "- Top k similar movies with similarity scores and their generated genres\n",
    "- Other movies sharing the same cluster assignment\n",
    "\n",
    "This multi-faceted approach provides comprehensive recommendations from different analytical perspectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(query_title, vectorized_data, hybrid_sim, title_to_idx, k=10):\n",
    "    if query_title not in title_to_idx:\n",
    "        suggestions = [t for t in title_to_idx.keys() if query_title in t][:5]\n",
    "        print(f\"Movie '{query_title}' not found. Suggestions: {suggestions}\")\n",
    "        return []\n",
    "    \n",
    "    q_idx = title_to_idx[query_title]\n",
    "    scores = hybrid_sim[q_idx]\n",
    "    sorted_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    recs = [(vectorized_data[i], scores[i]) for i in sorted_idx if i != q_idx][:k]\n",
    "    return recs\n",
    "\n",
    "def get_cluster_members(query_title, vectorized_data, title_to_idx, max_n=5):\n",
    "    if query_title not in title_to_idx:\n",
    "        return []\n",
    "    q_cluster = vectorized_data[title_to_idx[query_title]]['cluster']\n",
    "    return [m for m in vectorized_data if m['cluster'] == q_cluster and m['movie_title'] != query_title][:max_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(query_title, vectorized_data, hybrid_sim, title_to_idx, k=10):\n",
    "    \"\"\"\n",
    "    Display comprehensive recommendations:\n",
    "    - Similar movies with scores and generated genres\n",
    "    - Movies from the same cluster\n",
    "    \"\"\"\n",
    "    if query_title not in title_to_idx:\n",
    "        print(f\"Movie '{query_title}' not found\")\n",
    "        return\n",
    "    \n",
    "    query = vectorized_data[title_to_idx[query_title]]\n",
    "    \n",
    "    # Header\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(f\"  RECOMMENDATIONS FOR: {query_title.upper()}\")\n",
    "    print(\"=\" * 95)\n",
    "    print(f\"  Year: {query['year']}  |  Rating: {query['content_rating']}  |  Cluster: {query['cluster']}\")\n",
    "    print(f\"  Original Genres: {query['genres']}\")\n",
    "    print(f\"  Generated Genres (LDA): {', '.join(query.get('generated_genres', ['N/A']))}\")\n",
    "    print(\"=\" * 95)\n",
    "    \n",
    "    # Similar Movies\n",
    "    similar = get_similar_movies(query_title, vectorized_data, hybrid_sim, title_to_idx, k)\n",
    "    \n",
    "    print(f\"\\n  TOP {k} SIMILAR MOVIES\")\n",
    "    print(\"  \" + \"-\" * 91)\n",
    "    print(f\"  {'RANK':<5}{'TITLE':<40}{'SCORE':<8}{'YEAR':<6}{'GENERATED GENRES (LDA)'}\")\n",
    "    print(\"  \" + \"-\" * 91)\n",
    "    \n",
    "    for i, (m, score) in enumerate(similar, 1):\n",
    "        title = m['movie_title'][:37] + \"...\" if len(m['movie_title']) > 40 else m['movie_title']\n",
    "        genres = ', '.join(m.get('generated_genres', ['N/A'])[:2])\n",
    "        print(f\"  {i:<5}{title:<40}{score:<8.4f}{m['year']:<6}{genres}\")\n",
    "    \n",
    "    # Cluster Members\n",
    "    cluster_members = get_cluster_members(query_title, vectorized_data, title_to_idx, 5)\n",
    "    \n",
    "    print(f\"\\n  OTHER MOVIES IN CLUSTER {query['cluster']}\")\n",
    "    print(\"  \" + \"-\" * 91)\n",
    "    \n",
    "    if cluster_members:\n",
    "        for m in cluster_members:\n",
    "            title = m['movie_title'][:45] + \"...\" if len(m['movie_title']) > 48 else m['movie_title']\n",
    "            print(f\"  • {title:<50} ({m['year']}) - {m['genres'][:35]}\")\n",
    "    else:\n",
    "        print(\"  No other movies in this cluster.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "  RECOMMENDATIONS FOR: ALIENS\n",
      "===============================================================================================\n",
      "  Year: 1986  |  Rating: r  |  Cluster: 2\n",
      "  Original Genres: action & adventure, horror, science fiction & fantasy\n",
      "  Generated Genres (LDA): Documentary (92%), International (7%)\n",
      "===============================================================================================\n",
      "\n",
      "  TOP 10 SIMILAR MOVIES\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  RANK TITLE                                   SCORE   YEAR  GENERATED GENRES (LDA)\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  1    escape from new york                    0.7539  1981  International (69%), Romance (30%)\n",
      "  2    appurushîdo (appleseed)                 0.6883  2004  Comedy/Light (98%)\n",
      "  3    the amityville horror                   0.6862  2005  Adventure/Epic (44%), Romance (36%)\n",
      "  4    razorback                               0.6484  1984  Documentary (98%)\n",
      "  5    kalifornia                              0.6412  1993  International (68%), Crime/Mystery (29%)\n",
      "  6    hacksaw ridge                           0.6385  2016  Family/Animation (91%), Romance (5%)\n",
      "  7    elfie hopkins                           0.6254  2012  Documentary (75%), Crime/Mystery (22%)\n",
      "  8    coogan's bluff                          0.5982  1968  International (97%)\n",
      "  9    the bone collector                      0.5947  1999  Documentary (99%)\n",
      "  10   sexy beast                              0.5908  2000  International (60%), Family/Animation (26%)\n",
      "\n",
      "  OTHER MOVIES IN CLUSTER 2\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  â€¢ escape from new york                               (1981) - action & adventure, science fiction\n",
      "  â€¢ appurushîdo (appleseed)                            (2004) - action & adventure, animation, anim\n",
      "  â€¢ milarepa                                           (2007) - action & adventure, art house & int\n",
      "  â€¢ pokémon the first movie - mewtwo vs. mew           (1999) - action & adventure, animation\n",
      "  â€¢ the seeker: the dark is rising                     (2007) - action & adventure, drama, science \n",
      "\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the recommendation system\n",
    "display_recommendations('aliens', vectorized_data, hybrid_sim, title_to_idx, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "  RECOMMENDATIONS FOR: TOY STORY\n",
      "===============================================================================================\n",
      "  Year: 1995  |  Rating: g  |  Cluster: 3\n",
      "  Original Genres: animation, comedy, kids & family\n",
      "  Generated Genres (LDA): Romance (72%), Family/Animation (14%), Crime/Mystery (12%)\n",
      "===============================================================================================\n",
      "\n",
      "  TOP 10 SIMILAR MOVIES\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  RANK TITLE                                   SCORE   YEAR  GENERATED GENRES (LDA)\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  1    frosty the snowman                      0.7284  1969  Sports (97%)\n",
      "  2    pokémon the first movie - mewtwo vs. mew0.6637  1999  Adventure/Epic (69%), Family/Animation (29%)\n",
      "  3    grown ups 2                             0.4952  2013  Adventure/Epic (77%), Romance (22%)\n",
      "  4    teenage mutant ninja turtles ii - the...0.4928  1991  Drama/Character (98%)\n",
      "  5    boat trip                               0.4803  2003  Adventure/Epic (40%), Crime/Mystery (33%)\n",
      "  6    lupin iii: the castle of cagliostro (...0.4574  2000  Romance (59%), Family/Animation (22%)\n",
      "  7    broken english                          0.4339  2007  Crime/Mystery (99%)\n",
      "  8    afternoon delight                       0.4329  2013  Crime/Mystery (87%), Family/Animation (11%)\n",
      "  9    sexy beast                              0.4291  2000  International (60%), Family/Animation (26%)\n",
      "  10   rocketman                               0.4245  1997  Drama/Character (64%), Crime/Mystery (33%)\n",
      "\n",
      "  OTHER MOVIES IN CLUSTER 3\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  â€¢ frosty the snowman                                 (1969) - animation, kids & family\n",
      "  â€¢ teenage mutant ninja turtles ii - the secret ...   (1991) - action & adventure, comedy, kids & \n",
      "\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "display_recommendations('toy story', vectorized_data, hybrid_sim, title_to_idx, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "  RECOMMENDATIONS FOR: THE GODFATHER\n",
      "===============================================================================================\n",
      "  Year: 1972  |  Rating: r  |  Cluster: 0\n",
      "  Original Genres: drama\n",
      "  Generated Genres (LDA): Sci-Fi/Fantasy (99%)\n",
      "===============================================================================================\n",
      "\n",
      "  TOP 10 SIMILAR MOVIES\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  RANK TITLE                                   SCORE   YEAR  GENERATED GENRES (LDA)\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  1    black irish                             0.7995  2007  Sports (97%)\n",
      "  2    the liberator                           0.7549  2014  Family/Animation (82%), Comedy/Light (9%)\n",
      "  3    1911                                    0.7251  2011  Family/Animation (52%), Romance (45%)\n",
      "  4    kalifornia                              0.7232  1993  International (68%), Crime/Mystery (29%)\n",
      "  5    sex and lucia                           0.7191  2002  Family/Animation (99%)\n",
      "  6    sleeping with the enemy                 0.7166  1991  International (99%)\n",
      "  7    descent                                 0.6947  2007  Family/Animation (84%), Crime/Mystery (14%)\n",
      "  8    mortal thoughts                         0.6945  1991  Family/Animation (76%), Documentary (19%)\n",
      "  9    afternoon delight                       0.6935  2013  Crime/Mystery (87%), Family/Animation (11%)\n",
      "  10   coogan's bluff                          0.6924  1968  International (97%)\n",
      "\n",
      "  OTHER MOVIES IN CLUSTER 0\n",
      "  -------------------------------------------------------------------------------------------\n",
      "  â€¢ black irish                                        (2007) - drama\n",
      "  â€¢ obsessed                                           (2009) - drama, mystery & suspense\n",
      "  â€¢ 1911                                               (2011) - drama\n",
      "  â€¢ afternoon delight                                  (2013) - comedy, drama\n",
      "  â€¢ angels in stardust                                 (2014) - comedy, drama\n",
      "\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "display_recommendations('the godfather', vectorized_data, hybrid_sim, title_to_idx, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Results and Evaluation\n",
    "\n",
    "This section provides a summary of the complete system, including dataset statistics, the similarity components used, clustering configuration, and topic modeling setup. The evaluation is primarily qualitative, examining whether recommendations align with expected movie relationships. Quantitative metrics like silhouette scores and Davies-Bouldin index are used to validate the clustering component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROJECT SUMMARY\n",
      "============================================================\n",
      "\n",
      "Dataset: 48 movies, 2,876 reviews\n",
      "\n",
      "Similarity Components: Info embeddings, Content rating, Genre, Year, Review style, Review type\n",
      "\n",
      "Clustering: K-Means with k=8\n",
      "\n",
      "Outside Topic: LDA with 15 topics for automatic genre generation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset: {len(vectorized_data):,} movies, {sum(len(m['reviews']) for m in vectorized_data):,} reviews\")\n",
    "print(f\"\\nSimilarity Components: Info embeddings, Content rating, Genre, Year, Review style, Review type\")\n",
    "print(f\"\\nClustering: K-Means with k={OPTIMAL_K}\")\n",
    "print(f\"\\nOutside Topic: LDA with {NUM_TOPICS} topics for automatic genre generation\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
