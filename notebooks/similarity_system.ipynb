{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca416209",
   "metadata": {},
   "source": [
    "# Similarity-Based Movie Recommendation System\n",
    "\n",
    "This notebook implements a hybrid similarity system to recommend movies.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Our system combines **6 different similarity metrics** to find movies similar to a query movie:\n",
    "\n",
    "1. **Info Similarity** - Based on movie description embeddings\n",
    "2. **Genre Similarity** - Based on genre overlap (action, drama, etc.)\n",
    "3. **Year Similarity** - Based on release year proximity\n",
    "4. **Content Rating Similarity** - Based on age rating (PG, R, etc.)\n",
    "5. **Review Style Similarity** - Based on how critics write about the movie\n",
    "6. **Review Type Similarity** - Based on fresh/rotten patterns across critics\n",
    "\n",
    "## Key Technologies\n",
    "\n",
    "- **Sentence Transformers** - Converts text to 384-dimensional embeddings\n",
    "- **Cosine Similarity** - Measures similarity between vectors\n",
    "- **Hybrid Scoring** - Weighted combination of all metrics\n",
    "\n",
    "## Process\n",
    "\n",
    "1. Load and group data by movie\n",
    "2. Vectorize movie data (convert to numbers)\n",
    "3. Build similarity matrices\n",
    "4. Combine into hybrid score\n",
    "5. Query for similar movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc4e5d",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f752ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e797f1",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Define Global Variables\n",
    "\n",
    "These are all possible genres and age ratings in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77b6c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = [\n",
    "    'science fiction & fantasy', 'drama', 'western', 'comedy', 'classics',\n",
    "    'action & adventure', 'kids & family', 'musical & performing arts',\n",
    "    'documentary', 'art house & international', 'horror', 'sports & fitness',\n",
    "    'faith & spirituality', 'mystery & suspense', 'animation', 'special interest', 'romance'\n",
    "]\n",
    "#no 'nr' to make it a neutral vector if its in the rating\n",
    "all_age_ratings = ['pg', 'r', 'g', 'pg-13', 'nc17']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af413f80",
   "metadata": {},
   "source": [
    "## Step 3: Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset() -> pd.DataFrame:\n",
    "\n",
    "    dataset = ''\n",
    "\n",
    "    final_dataset = pd.read_csv(dataset)\n",
    "\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7d910a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group() -> list[dict]:\n",
    "\n",
    "    final_dataset = get_dataset()\n",
    "    \n",
    "    #group movies together\n",
    "    grouped = final_dataset.groupby('rotten_tomatoes_link')\n",
    "\n",
    "    movie_data = []\n",
    "\n",
    "    for movie_id, group in grouped:\n",
    "\n",
    "        #Critic data\n",
    "        reviews = group['review_content'].tolist()\n",
    "        critic_names = group['critic_name'].to_list()\n",
    "        review_types = group['review_type'].to_list()\n",
    "\n",
    "        # Get metadata (take first row since they're all the same)\n",
    "        first_row = group.iloc[0]\n",
    "\n",
    "        #append dict of each movie\n",
    "        movie_data.append({\n",
    "            'movie_id': movie_id,\n",
    "            'movie_title': first_row['movie_title'],\n",
    "            'content_rating': first_row['content_rating'],\n",
    "            'genres': first_row['genres'],\n",
    "            'year': first_row['original_release_date'],\n",
    "            'movie_info': first_row['movie_info'], #List of all review info texts\n",
    "\n",
    "            #Per critic data\n",
    "            'reviews': reviews,  # List of all review texts\n",
    "            'critic_names': critic_names,   #List of all critic names\n",
    "            'review_types': review_types, #List of all review types\n",
    "\n",
    "        })\n",
    "        \n",
    "    #minimum amount of reviews\n",
    "    min_reviews = 5\n",
    "\n",
    "    movie_data_filtered = [\n",
    "        movie for movie in movie_data\n",
    "        if len(movie['reviews']) >= min_reviews\n",
    "    ]\n",
    "    \n",
    "    print(f\"Loaded {len(movie_data_filtered)} movies with ≥{min_reviews} reviews\")\n",
    "    movie_data = movie_data_filtered\n",
    "\n",
    "    return movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515be1f",
   "metadata": {},
   "source": [
    "## Step 4: Vectorization Functions\n",
    "\n",
    "**Goal:** Convert text and categories to numbers that we can compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53930446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embeddings for content and review style\n",
    "def vectorize(movie_data: list) -> list[dict]:\n",
    "\n",
    "    #creates binary list of genres \n",
    "    def encode_genres(movie_genres:list,all_genres:list):\n",
    "        return [1 if genre in movie_genres else 0 for genre in all_genres]\n",
    "    \n",
    "    #creates binary list of ratings\n",
    "    def encode_content_rating(content_rating,all_content_ratings):\n",
    "        return [1 if cr == content_rating else 0 for cr in all_content_ratings]\n",
    "    \n",
    "    def encode_review_type(review_types):\n",
    "        return [1 if rt == \"fresh\" else 0 for rt in review_types]\n",
    "       \n",
    "    print(\"Initializing sentence transformer...\")\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    #normalize year range\n",
    "    year = [movie['year'] for movie in movie_data if movie['year'] > 0]\n",
    "    min_year = min(year)\n",
    "    max_year = max(year)\n",
    "\n",
    "    total_movies = len(movie_data)\n",
    "\n",
    "    for i, movie in enumerate(movie_data, start=1):\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Processing movie {i}/{total_movies} ({i/total_movies*100:.1f}%) - {movie['movie_title']}\")\n",
    "\n",
    "        # Encode all movie infos for this movie\n",
    "        movie['movie_info_embeddings'] = model.encode(movie['movie_info'])\n",
    "\n",
    "        #Content rating\n",
    "        movie['content_rating_norm'] = encode_content_rating(movie['content_rating'],all_age_ratings)\n",
    "\n",
    "        #Genres\n",
    "        movie['genre_vector'] = encode_genres(movie['genres'], all_genres)\n",
    "\n",
    "        #Year\n",
    "        movie['year_norm'] = (movie['year'] - min_year) / (max_year - min_year)\n",
    "\n",
    "        # Encode all reviews for this movie\n",
    "        review_embeddings = model.encode(movie['reviews'])# Shape: (num_reviews, 384)\n",
    "        #Average to get single movie embedding\n",
    "        movie['avg_review_embeddings'] = review_embeddings.mean(axis=0)\n",
    "\n",
    "        #review type\n",
    "        movie['review_types_norm'] = encode_review_type(movie['review_types'])\n",
    "       \n",
    "    vectorized_movie_data = movie_data\n",
    "\n",
    "    return vectorized_movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02117365",
   "metadata": {},
   "source": [
    "Checks if vectorized movie data pickle exists. If not, generate, save, and return it\n",
    "\n",
    "**Caching:** Results saved to `../cache/vectorized_movie_data.pkl` so we don't recompute (takes ~10-20 minutes first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f947e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_vectorized_data(pickle_path=\"../cache/vectorized_movie_data.pkl\") -> list[dict]:\n",
    "    if os.path.exists(pickle_path):\n",
    "        print(f\"Loading vectorized movie data from {pickle_path}...\")\n",
    "        with open(pickle_path, \"rb\") as f:\n",
    "            vectorized_movie_data = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Pickle file not found. Generating vectorized movie data...\")\n",
    "        grouped = group()\n",
    "        vectorized_movie_data = vectorize(grouped)\n",
    "        with open(pickle_path, \"wb\") as f:\n",
    "            pickle.dump(vectorized_movie_data, f)\n",
    "        print(f\"Vectorized movie data saved to {pickle_path}.\")\n",
    "    return vectorized_movie_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9512f4f",
   "metadata": {},
   "source": [
    "## Step 5: Similarity Matrix Functions\n",
    "\n",
    "**Goal:** Create 6 separate similarity matrices, each capturing a different aspect\n",
    "\n",
    "Each function:\n",
    "1. Stacks all movie vectors into a matrix (one row per movie)\n",
    "2. Computes pairwise cosine similarity\n",
    "3. Returns matrix where `matrix[i][j]` = similarity between movie i and movie j\n",
    "\n",
    "**Similarity matrices:**\n",
    "\n",
    "1. **Info** - Based on movie description embeddings (semantic meaning)\n",
    "2. **Genre** - Based on genre overlap (how many genres they share)\n",
    "3. **Year** - Based on release year proximity (1999 vs 2000 = very similar)\n",
    "4. **Content Rating** - Based on age rating match (both R-rated = similar)\n",
    "5. **Style** - Based on review writing style (how critics describe them)\n",
    "6. **Type** - Based on fresh/rotten patterns across critics (correlation of ratings)\n",
    "\n",
    "**Cosine Similarity:** Ranges 0-1 where:\n",
    "- 1.0 = identical\n",
    "- 0.5 = somewhat similar\n",
    "- 0.0 = completely different\n",
    "\n",
    "**Caching:** All matrices saved to `../cache/similarity_matrices.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "edc1a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_info_sim(vectorized_movie_data) -> np.ndarray:\n",
    "\n",
    "    info_vectors = np.vstack([movie['movie_info_embeddings'] for movie in vectorized_movie_data])\n",
    "\n",
    "    #pairwise cosine similarity\n",
    "    info_sim = cosine_similarity(info_vectors).astype('float32')\n",
    "\n",
    "    print(f\"Info similarity matrix: {info_sim.shape}\")\n",
    "\n",
    "    return info_sim\n",
    "\n",
    "\n",
    "def build_content_rating_sim(vectorized_movie_data) -> np.ndarray:\n",
    "\n",
    "    content_rating_vectors = np.vstack([movie['content_rating_norm'] for movie in vectorized_movie_data])\n",
    "\n",
    "    #pairwise cosine similarity\n",
    "    content_rating_sim = cosine_similarity(content_rating_vectors).astype('float32')\n",
    "\n",
    "    print(f\"Content rating similarity matrix: {content_rating_sim.shape}\")\n",
    "\n",
    "    return content_rating_sim\n",
    "\n",
    "def build_genre_sim(vectorized_movie_data) -> np.ndarray:\n",
    "\n",
    "    genre_vectors = np.vstack([movie['genre_vector'] for movie in vectorized_movie_data])\n",
    "\n",
    "    #pairwise cosine similarity\n",
    "    genre_sim = cosine_similarity(genre_vectors).astype('float32')\n",
    "\n",
    "    print(f\"Genre similarity matrix: {genre_sim.shape}\")\n",
    "\n",
    "    return genre_sim\n",
    "\n",
    "def build_year_sim(vectorized_movie_data) -> np.ndarray:\n",
    "\n",
    "    year_vectors = np.vstack([movie['year_norm'] for movie in vectorized_movie_data])\n",
    "\n",
    "    #pairwise cosine similarity\n",
    "    year_sim = cosine_similarity(year_vectors).astype('float32')\n",
    "\n",
    "    print(f\"Year similarity matrix: {year_sim.shape}\")\n",
    "\n",
    "    return year_sim\n",
    "\n",
    "#content\n",
    "def build_content_sim(vectorized_movie_data) -> np.ndarray:\n",
    "\n",
    "    content_vectors = np.vstack([movie['content_vector'] for movie in vectorized_movie_data])\n",
    "\n",
    "    #pairwise cosine similarity\n",
    "    content_sim = cosine_similarity(content_vectors).astype('float32')\n",
    "\n",
    "    print(f\"Content similarity matrix: {content_sim.shape}\")\n",
    "\n",
    "    return content_sim\n",
    "    \n",
    "#style\n",
    "def build_review_style_sim(vectorized_movie_data) -> np.ndarray:\n",
    "    \n",
    "    review_embeddings = np.vstack([movie['avg_review_embeddings'] for movie in vectorized_movie_data])\n",
    "\n",
    "    #pairwise cosine similarity\n",
    "    review_sim = cosine_similarity(review_embeddings).astype('float32')\n",
    "\n",
    "    print(f\"Review similarity matrix: {review_sim.shape}\")\n",
    "\n",
    "    return review_sim\n",
    "\n",
    "def build_review_type_sim(vectorized_movie_data) -> np.ndarray:\n",
    "\n",
    "    #Get all critics\n",
    "    all_critics = set()\n",
    "    for movie in vectorized_movie_data:\n",
    "        all_critics.update(movie['critic_names'])\n",
    "    all_critics = sorted(all_critics)\n",
    "\n",
    "    #Get all movie titles\n",
    "    all_movies = [movie['movie_title'] for movie in vectorized_movie_data]\n",
    "    \n",
    "    #create Movie x Critic matrix\n",
    "    matrix = pd.DataFrame(np.nan, index = all_movies, columns=all_critics)\n",
    "\n",
    "    #Fill in review scores\n",
    "    for movie in vectorized_movie_data:\n",
    "\n",
    "        mit = movie['movie_title']\n",
    "\n",
    "        for critic,review_type in zip(movie['critic_names'], movie['review_types_norm']):\n",
    "            matrix.loc[mit,critic] = review_type\n",
    "\n",
    "    #Pearson correlation movie x movie (1 to -1)\n",
    "    type_sim = matrix.T.corr(method='pearson')\n",
    "\n",
    "    # normalize to 0-1\n",
    "    type_sim = (type_sim + 1) / 2\n",
    "\n",
    "    #convert to np array\n",
    "    type_sim_array = type_sim.values\n",
    "\n",
    "    #fill empty pairs with 0.5(neutral)\n",
    "    type_sim = np.nan_to_num(type_sim_array, nan=0.5)\n",
    "\n",
    "    print(f\"Type similarity matrix: {type_sim.shape}\")\n",
    "\n",
    "    return type_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0d71c",
   "metadata": {},
   "source": [
    "Checks if similarity matrices pickle exists. If not, generate, save, and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2071e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_similarity_matrices(vectorized_data, pickle_path=\"../cache/similarity_matrices.pkl\"):\n",
    "    \"\"\"Load or compute all similarity matrices\"\"\"\n",
    "    \n",
    "    if os.path.exists(pickle_path):\n",
    "        print(f\"Loading similarity matrices from {pickle_path}...\")\n",
    "        with open(pickle_path, \"rb\") as f:\n",
    "            matrices = pickle.load(f)\n",
    "        info_sim = matrices['info']\n",
    "        content_rating_sim = matrices['content_rating']\n",
    "        genre_sim = matrices['genre']\n",
    "        year_sim = matrices['year']\n",
    "        style_sim = matrices['style']\n",
    "        type_sim = matrices['type']\n",
    "    else:\n",
    "        print(\"Pickle file not found. Computing similarity matrices...\")\n",
    "        info_sim = build_info_sim(vectorized_data)\n",
    "        content_rating_sim = build_content_rating_sim(vectorized_data)\n",
    "        genre_sim = build_genre_sim(vectorized_data)\n",
    "        year_sim = build_year_sim(vectorized_data)\n",
    "        style_sim = build_review_style_sim(vectorized_data)\n",
    "        type_sim = build_review_type_sim(vectorized_data)\n",
    "        \n",
    "        print(f\"Saving similarity matrices to {pickle_path}...\")\n",
    "        with open(pickle_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                'info': info_sim,\n",
    "                'content_rating': content_rating_sim,\n",
    "                'genre': genre_sim,\n",
    "                'year': year_sim,\n",
    "                'style': style_sim,\n",
    "                'type': type_sim\n",
    "            }, f)\n",
    "    \n",
    "    return info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755d1ad",
   "metadata": {},
   "source": [
    "## Step 6: Hybrid Scoring\n",
    "\n",
    "**Goal:** Combine all 6 similarity matrices into one final score\n",
    "\n",
    "**Method:** Weighted sum\n",
    "- Each similarity matrix gets a weight (α, β, γ, δ, ε, ζ)\n",
    "- Final similarity = weighted average of all 6 scores\n",
    "\n",
    "**Current weights:**\n",
    "- α (alpha) = 0.2 → Info similarity (movie description)\n",
    "- β (beta) = 0.2 → Content rating similarity\n",
    "- γ (gamma) = 0.2 → Genre similarity\n",
    "- δ (delta) = 0.2 → Year similarity\n",
    "- ε (epsilon) = 0.1 → Review style similarity\n",
    "- ζ (zeta) = 0.1 → Review type similarity\n",
    "\n",
    "**Total = 1.0** (weights must sum to 1)\n",
    "\n",
    "**You can experiment with different weights!** For example:\n",
    "- Emphasize genre: `gamma = 0.4`\n",
    "- Ignore year: `delta = 0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d5629805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_score(info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim, alpha, beta, gamma, delta, epsilon, zeta):\n",
    "    \n",
    "    hybrid_sim = (alpha * info_sim) + (beta * content_rating_sim) + (gamma * genre_sim) + (delta * year_sim) + (epsilon * style_sim) + (zeta * type_sim)\n",
    "\n",
    "    return hybrid_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296eaff5",
   "metadata": {},
   "source": [
    "## Step 7: Query Function\n",
    "\n",
    "**Goal:** Find movies most similar to a query movie\n",
    "\n",
    "**Process:**\n",
    "1. Find the query movie in our dataset (by title)\n",
    "2. Get its row from the hybrid similarity matrix\n",
    "3. Sort all movies by similarity score (highest first)\n",
    "4. Return top k movies (excluding the query itself)\n",
    "\n",
    "**Parameters:**\n",
    "- `movie_title` - Name of movie to find similar to (lowercase)\n",
    "- `k` - Number of recommendations to return (default 10)\n",
    "\n",
    "**Output:** Prints a formatted table of recommendations with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6af3c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_movie(movie_title,vectorized_movie_data,hybrid_sim,k=10):\n",
    "\n",
    "    #Find iterable of query movie\n",
    "    query_id = None\n",
    "    for i,movie in enumerate(vectorized_movie_data):\n",
    "        if movie['movie_title'] == movie_title:\n",
    "            query_id = i\n",
    "            break\n",
    "   \n",
    "    #row of hybrid sim scores sorted\n",
    "    sim = hybrid_sim[query_id]\n",
    "    sorted_indices = np.argsort(sim)[::-1]\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for pos in sorted_indices[1:k+1]:\n",
    "        recommendations.append((vectorized_movie_data[pos]['movie_title'], sim[pos]))\n",
    "\n",
    "    ################################\n",
    "    max_len = max(len(movie) for movie, _ in recommendations)\n",
    "    print()\n",
    "    print(f\"Query movie: {movie_title}\")\n",
    "    print()\n",
    "    print(\"MOVIE\".ljust(max_len)  +  \"  SCORE\")\n",
    "\n",
    "    for m,s in recommendations:\n",
    "        score = round(s,2)\n",
    "        print(f'{m:{max_len}}  {score}')\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349874e",
   "metadata": {},
   "source": [
    "## Step 8: Load All Data and Compute Similarities\n",
    "\n",
    "**This cell does everything:**\n",
    "\n",
    "1. **Load vectorized data** (or create if first time)\n",
    "   - If cached: loads in ~10 seconds\n",
    "   - If not cached: takes ~10-30 minutes to compute\n",
    "\n",
    "2. **Load similarity matrices** (or create if first time)\n",
    "   - If cached: loads in ~5 seconds\n",
    "   - If not cached: takes ~2-5 minutes to compute\n",
    "\n",
    "3. **Compute hybrid similarity**\n",
    "   - Combines all 6 matrices with weights\n",
    "   - Takes ~1 second\n",
    "\n",
    "**After this runs, the system is ready to query!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cadf0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectorized movie data from ../cache/vectorized_movie_data.pkl...\n",
      "Loading similarity matrices from ../cache/similarity_matrices.pkl...\n",
      "System ready\n"
     ]
    }
   ],
   "source": [
    "# Load or create vectorized data\n",
    "vectorized_data = load_or_create_vectorized_data('../cache/vectorized_movie_data.pkl')\n",
    "\n",
    "# Load or create similarity matrices  \n",
    "info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim = load_or_create_similarity_matrices(\n",
    "    vectorized_data, \n",
    "    '../cache/similarity_matrices.pkl'\n",
    ")\n",
    "\n",
    "# Compute hybrid similarity\n",
    "hybrid_sim = hybrid_score(info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim, \n",
    "                          0.2, 0.2, 0.2, 0.2, 0.1, 0.1)\n",
    "\n",
    "print(\"System ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b6117",
   "metadata": {},
   "source": [
    "\n",
    "## Step 9: Query for Similar Movies!\n",
    "\n",
    "Change `\"aliens\"` to any movie title in the dataset (lowercase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4aff01b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query movie: aliens\n",
      "\n",
      "MOVIE                                 SCORE\n",
      "alien3                                0.83\n",
      "lifeforce                             0.82\n",
      "virus                                 0.82\n",
      "alien resurrection                    0.81\n",
      "contamination                         0.8\n",
      "underworld: awakening                 0.8\n",
      "doom                                  0.8\n",
      "pandorum                              0.8\n",
      "aliens vs. predator: requiem (avp 2)  0.8\n",
      "deepstar six                          0.8\n"
     ]
    }
   ],
   "source": [
    "# Query Example\n",
    "\n",
    "query_movie(\"aliens\", vectorized_data, hybrid_sim, k=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943d185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
