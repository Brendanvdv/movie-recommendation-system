{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Similarity System Visualizations\n",
        "\n",
        "Three focused visualizations for the hybrid movie recommendation system:\n",
        "\n",
        "1. **Component Contribution Breakdown** - Shows how each similarity component contributes to the final hybrid score for recommendations (the key visualization)\n",
        "2. **Similarity Distribution Comparison** - Box plots of each matrix's value distribution\n",
        "3. **Weight Sensitivity Analysis** - How different weight configurations affect recommendations"
      ],
      "metadata": {
        "id": "viz_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Run your existing data loading code first, then add these visualization cells."
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Set plotting style\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Visualization 1: Component Contribution Breakdown\n",
        "\n",
        "This is the key visualization — a stacked bar chart showing how much each similarity component (info embedding, genre, year, etc.) contributes to the final hybrid score of each recommendation.\n",
        "\n",
        "**Why this matters:**\n",
        "- Answers \"What's actually driving these recommendations?\"\n",
        "- Exposes if one component dominates the scoring\n",
        "- Demonstrates transparency in the hybrid approach"
      ],
      "metadata": {
        "id": "viz1_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_component_contributions(query_title, vectorized_data, \n",
        "                                  info_sim, content_rating_sim, genre_sim, \n",
        "                                  year_sim, style_sim, type_sim,\n",
        "                                  weights=(0.2, 0.2, 0.2, 0.2, 0.1, 0.1), \n",
        "                                  top_k=5):\n",
        "    \"\"\"\n",
        "    Stacked bar chart showing the contribution of each similarity component\n",
        "    to the final hybrid score for top-k recommendations.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    query_title : str - The movie to find recommendations for\n",
        "    vectorized_data : list - List of movie dictionaries\n",
        "    *_sim : np.ndarray - Individual similarity matrices\n",
        "    weights : tuple - (alpha, beta, gamma, delta, epsilon, zeta)\n",
        "    top_k : int - Number of recommendations to display\n",
        "    \"\"\"\n",
        "    # Unpack weights\n",
        "    alpha, beta, gamma, delta, epsilon, zeta = weights\n",
        "    \n",
        "    # Find query movie index\n",
        "    query_idx = None\n",
        "    for i, movie in enumerate(vectorized_data):\n",
        "        if movie['movie_title'].lower() == query_title.lower():\n",
        "            query_idx = i\n",
        "            break\n",
        "    \n",
        "    if query_idx is None:\n",
        "        print(f\"Movie '{query_title}' not found.\")\n",
        "        return\n",
        "    \n",
        "    # Calculate hybrid scores\n",
        "    hybrid_sim = (alpha * info_sim + beta * content_rating_sim + \n",
        "                  gamma * genre_sim + delta * year_sim + \n",
        "                  epsilon * style_sim + zeta * type_sim)\n",
        "    \n",
        "    # Get top-k recommendations\n",
        "    sim_scores = hybrid_sim[query_idx]\n",
        "    sorted_indices = np.argsort(sim_scores)[::-1]\n",
        "    top_indices = [idx for idx in sorted_indices if idx != query_idx][:top_k]\n",
        "    \n",
        "    # Get individual component contributions for each recommendation\n",
        "    movie_titles = []\n",
        "    info_contrib = []\n",
        "    rating_contrib = []\n",
        "    genre_contrib = []\n",
        "    year_contrib = []\n",
        "    style_contrib = []\n",
        "    type_contrib = []\n",
        "    \n",
        "    for idx in top_indices:\n",
        "        movie_titles.append(vectorized_data[idx]['movie_title'][:25])\n",
        "        info_contrib.append(alpha * info_sim[query_idx, idx])\n",
        "        rating_contrib.append(beta * content_rating_sim[query_idx, idx])\n",
        "        genre_contrib.append(gamma * genre_sim[query_idx, idx])\n",
        "        year_contrib.append(delta * year_sim[query_idx, idx])\n",
        "        style_contrib.append(epsilon * style_sim[query_idx, idx])\n",
        "        type_contrib.append(zeta * type_sim[query_idx, idx])\n",
        "    \n",
        "    # Create stacked bar chart\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    x = np.arange(len(movie_titles))\n",
        "    width = 0.6\n",
        "    \n",
        "    # Stack the bars\n",
        "    bars1 = ax.bar(x, info_contrib, width, label=f'Info Embedding (α={alpha})', color='#2ecc71')\n",
        "    bars2 = ax.bar(x, rating_contrib, width, bottom=info_contrib, \n",
        "                   label=f'Content Rating (β={beta})', color='#3498db')\n",
        "    bars3 = ax.bar(x, genre_contrib, width, \n",
        "                   bottom=np.array(info_contrib) + np.array(rating_contrib),\n",
        "                   label=f'Genre (γ={gamma})', color='#9b59b6')\n",
        "    bars4 = ax.bar(x, year_contrib, width,\n",
        "                   bottom=np.array(info_contrib) + np.array(rating_contrib) + np.array(genre_contrib),\n",
        "                   label=f'Year (δ={delta})', color='#f39c12')\n",
        "    bars5 = ax.bar(x, style_contrib, width,\n",
        "                   bottom=np.array(info_contrib) + np.array(rating_contrib) + np.array(genre_contrib) + np.array(year_contrib),\n",
        "                   label=f'Review Style (ε={epsilon})', color='#e74c3c')\n",
        "    bars6 = ax.bar(x, type_contrib, width,\n",
        "                   bottom=np.array(info_contrib) + np.array(rating_contrib) + np.array(genre_contrib) + np.array(year_contrib) + np.array(style_contrib),\n",
        "                   label=f'Review Type (ζ={zeta})', color='#1abc9c')\n",
        "    \n",
        "    # Add total score labels on top\n",
        "    totals = [sum(x) for x in zip(info_contrib, rating_contrib, genre_contrib, \n",
        "                                   year_contrib, style_contrib, type_contrib)]\n",
        "    for i, total in enumerate(totals):\n",
        "        ax.text(i, total + 0.01, f'{total:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "    \n",
        "    ax.set_xlabel('Recommended Movies', fontsize=11)\n",
        "    ax.set_ylabel('Weighted Similarity Contribution', fontsize=11)\n",
        "    ax.set_title(f'Hybrid Score Component Breakdown\\nQuery: \"{query_title}\"', fontsize=13, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(movie_titles, rotation=45, ha='right', fontsize=9)\n",
        "    ax.legend(loc='upper right', fontsize=8)\n",
        "    ax.set_ylim(0, max(totals) * 1.15)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print numerical breakdown\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Component Contribution Analysis for Query: {query_title}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'Movie':<28} {'Info':>8} {'Rating':>8} {'Genre':>8} {'Year':>8} {'Style':>8} {'Type':>8} {'TOTAL':>8}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    for i, title in enumerate(movie_titles):\n",
        "        print(f\"{title:<28} {info_contrib[i]:>8.4f} {rating_contrib[i]:>8.4f} {genre_contrib[i]:>8.4f} \"\n",
        "              f\"{year_contrib[i]:>8.4f} {style_contrib[i]:>8.4f} {type_contrib[i]:>8.4f} {totals[i]:>8.4f}\")"
      ],
      "metadata": {
        "id": "viz1_function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage - uncomment and modify after loading your data\n",
        "# plot_component_contributions(\n",
        "#     query_title=\"Alien\",\n",
        "#     vectorized_data=vectorized_data,\n",
        "#     info_sim=info_sim,\n",
        "#     content_rating_sim=content_rating_sim,\n",
        "#     genre_sim=genre_sim,\n",
        "#     year_sim=year_sim,\n",
        "#     style_sim=style_sim,\n",
        "#     type_sim=type_sim,\n",
        "#     weights=(0.2, 0.2, 0.2, 0.2, 0.1, 0.1),\n",
        "#     top_k=5\n",
        "# )"
      ],
      "metadata": {
        "id": "viz1_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Visualization 2: Similarity Distribution Comparison\n",
        "\n",
        "Box plots showing the value distribution of each similarity matrix across all movie pairs.\n",
        "\n",
        "**Why this matters:**\n",
        "- Different matrices have different natural ranges and variances\n",
        "- Justifies why components might be weighted differently\n",
        "- Identifies degenerate matrices (e.g., clustering near 0.5)"
      ],
      "metadata": {
        "id": "viz2_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_similarity_distributions(info_sim, content_rating_sim, genre_sim, \n",
        "                                   year_sim, style_sim, type_sim):\n",
        "    \"\"\"\n",
        "    Box plots comparing the distribution of similarity values across all\n",
        "    movie pairs for each similarity component.\n",
        "    \"\"\"\n",
        "    # Sample upper triangle values (excluding diagonal) to avoid self-similarity\n",
        "    n = info_sim.shape[0]\n",
        "    upper_indices = np.triu_indices(n, k=1)\n",
        "    \n",
        "    # Extract values\n",
        "    data = {\n",
        "        'Info\\nEmbedding': info_sim[upper_indices],\n",
        "        'Content\\nRating': content_rating_sim[upper_indices],\n",
        "        'Genre': genre_sim[upper_indices],\n",
        "        'Year': year_sim[upper_indices],\n",
        "        'Review\\nStyle': style_sim[upper_indices],\n",
        "        'Review\\nType': type_sim[upper_indices]\n",
        "    }\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    # Create box plots\n",
        "    bp = ax.boxplot(data.values(), labels=data.keys(), patch_artist=True)\n",
        "    \n",
        "    # Color the boxes\n",
        "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#f39c12', '#e74c3c', '#1abc9c']\n",
        "    for patch, color in zip(bp['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "    \n",
        "    ax.set_ylabel('Similarity Value', fontsize=11)\n",
        "    ax.set_xlabel('Similarity Component', fontsize=11)\n",
        "    ax.set_title('Distribution of Similarity Values by Component\\n(All Movie Pairs)', \n",
        "                 fontsize=13, fontweight='bold')\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add mean markers\n",
        "    means = [np.mean(v) for v in data.values()]\n",
        "    ax.scatter(range(1, 7), means, marker='D', color='black', s=50, zorder=3, label='Mean')\n",
        "    ax.legend(loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print statistics\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"Similarity Matrix Statistics\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'Component':<20} {'Mean':>12} {'Std':>12} {'Min':>12} {'Max':>12} {'Median':>12}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    for name, values in data.items():\n",
        "        name_clean = name.replace('\\n', ' ')\n",
        "        print(f\"{name_clean:<20} {np.mean(values):>12.4f} {np.std(values):>12.4f} \"\n",
        "              f\"{np.min(values):>12.4f} {np.max(values):>12.4f} {np.median(values):>12.4f}\")"
      ],
      "metadata": {
        "id": "viz2_function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage - uncomment after loading your data\n",
        "# plot_similarity_distributions(\n",
        "#     info_sim=info_sim,\n",
        "#     content_rating_sim=content_rating_sim,\n",
        "#     genre_sim=genre_sim,\n",
        "#     year_sim=year_sim,\n",
        "#     style_sim=style_sim,\n",
        "#     type_sim=type_sim\n",
        "# )"
      ],
      "metadata": {
        "id": "viz2_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Visualization 3: Weight Sensitivity Analysis\n",
        "\n",
        "Line plot showing how varying each component's weight affects the average similarity score of top recommendations.\n",
        "\n",
        "**Why this matters:**\n",
        "- Justifies weight choices empirically\n",
        "- Shows which components have high discriminative power\n",
        "- Identifies components with low marginal impact"
      ],
      "metadata": {
        "id": "viz3_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_weight_sensitivity(query_title, vectorized_data,\n",
        "                            info_sim, content_rating_sim, genre_sim,\n",
        "                            year_sim, style_sim, type_sim,\n",
        "                            base_weights=(0.2, 0.2, 0.2, 0.2, 0.1, 0.1),\n",
        "                            top_k=10):\n",
        "    \"\"\"\n",
        "    Line plot showing how varying each weight (while keeping others proportional)\n",
        "    affects the average top-k recommendation score.\n",
        "    \"\"\"\n",
        "    # Find query movie index\n",
        "    query_idx = None\n",
        "    for i, movie in enumerate(vectorized_data):\n",
        "        if movie['movie_title'].lower() == query_title.lower():\n",
        "            query_idx = i\n",
        "            break\n",
        "    \n",
        "    if query_idx is None:\n",
        "        print(f\"Movie '{query_title}' not found.\")\n",
        "        return\n",
        "    \n",
        "    component_names = ['Info Embedding', 'Content Rating', 'Genre', 'Year', 'Review Style', 'Review Type']\n",
        "    sim_matrices = [info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim]\n",
        "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#f39c12', '#e74c3c', '#1abc9c']\n",
        "    \n",
        "    weight_range = np.linspace(0, 0.6, 20)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    for comp_idx, (name, sim_matrix, color) in enumerate(zip(component_names, sim_matrices, colors)):\n",
        "        avg_scores = []\n",
        "        \n",
        "        for target_weight in weight_range:\n",
        "            # Create weight vector with target weight for this component\n",
        "            # Distribute remaining weight proportionally among others\n",
        "            remaining = 1.0 - target_weight\n",
        "            weights = list(base_weights)\n",
        "            \n",
        "            # Calculate how much weight others had originally\n",
        "            original_other_sum = sum(w for i, w in enumerate(base_weights) if i != comp_idx)\n",
        "            \n",
        "            if original_other_sum > 0:\n",
        "                for i in range(6):\n",
        "                    if i == comp_idx:\n",
        "                        weights[i] = target_weight\n",
        "                    else:\n",
        "                        weights[i] = base_weights[i] / original_other_sum * remaining\n",
        "            else:\n",
        "                weights[comp_idx] = target_weight\n",
        "            \n",
        "            # Calculate hybrid similarity\n",
        "            hybrid = sum(w * m for w, m in zip(weights, sim_matrices))\n",
        "            \n",
        "            # Get top-k average score\n",
        "            scores = hybrid[query_idx]\n",
        "            sorted_scores = np.sort(scores)[::-1]\n",
        "            top_scores = sorted_scores[1:top_k+1]  # Exclude self\n",
        "            avg_scores.append(np.mean(top_scores))\n",
        "        \n",
        "        ax.plot(weight_range, avg_scores, label=name, color=color, linewidth=2, marker='o', markersize=3)\n",
        "    \n",
        "    # Mark base weights with vertical lines\n",
        "    for comp_idx, (name, color) in enumerate(zip(component_names, colors)):\n",
        "        ax.axvline(x=base_weights[comp_idx], color=color, linestyle='--', alpha=0.3)\n",
        "    \n",
        "    ax.set_xlabel('Component Weight', fontsize=11)\n",
        "    ax.set_ylabel(f'Average Top-{top_k} Similarity Score', fontsize=11)\n",
        "    ax.set_title(f'Weight Sensitivity Analysis\\nQuery: \"{query_title}\"', fontsize=13, fontweight='bold')\n",
        "    ax.legend(loc='best', fontsize=9)\n",
        "    ax.grid(alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "viz3_function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage - uncomment after loading your data\n",
        "# plot_weight_sensitivity(\n",
        "#     query_title=\"Alien\",\n",
        "#     vectorized_data=vectorized_data,\n",
        "#     info_sim=info_sim,\n",
        "#     content_rating_sim=content_rating_sim,\n",
        "#     genre_sim=genre_sim,\n",
        "#     year_sim=year_sim,\n",
        "#     style_sim=style_sim,\n",
        "#     type_sim=type_sim,\n",
        "#     base_weights=(0.2, 0.2, 0.2, 0.2, 0.1, 0.1),\n",
        "#     top_k=10\n",
        "# )"
      ],
      "metadata": {
        "id": "viz3_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Full Example: Load Data and Generate All Visualizations\n",
        "\n",
        "Copy the cells below into your main notebook after your data loading code."
      ],
      "metadata": {
        "id": "full_example_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your similarity.py functions are available:\n",
        "#\n",
        "# from similarity import load_or_create_vectorized_data, load_or_create_similarity_matrices\n",
        "#\n",
        "# vectorized_data = load_or_create_vectorized_data()\n",
        "# info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim = load_or_create_similarity_matrices(vectorized_data)\n",
        "#\n",
        "# # Then run all three visualizations:\n",
        "#\n",
        "# # 1. Component Contributions (KEY VISUALIZATION)\n",
        "# plot_component_contributions(\n",
        "#     query_title=\"Alien\",\n",
        "#     vectorized_data=vectorized_data,\n",
        "#     info_sim=info_sim,\n",
        "#     content_rating_sim=content_rating_sim,\n",
        "#     genre_sim=genre_sim,\n",
        "#     year_sim=year_sim,\n",
        "#     style_sim=style_sim,\n",
        "#     type_sim=type_sim,\n",
        "#     weights=(0.2, 0.2, 0.2, 0.2, 0.1, 0.1),\n",
        "#     top_k=5\n",
        "# )\n",
        "#\n",
        "# # 2. Similarity Distributions\n",
        "# plot_similarity_distributions(\n",
        "#     info_sim, content_rating_sim, genre_sim, year_sim, style_sim, type_sim\n",
        "# )\n",
        "#\n",
        "# # 3. Weight Sensitivity\n",
        "# plot_weight_sensitivity(\n",
        "#     query_title=\"Alien\",\n",
        "#     vectorized_data=vectorized_data,\n",
        "#     info_sim=info_sim,\n",
        "#     content_rating_sim=content_rating_sim,\n",
        "#     genre_sim=genre_sim,\n",
        "#     year_sim=year_sim,\n",
        "#     style_sim=style_sim,\n",
        "#     type_sim=type_sim,\n",
        "#     base_weights=(0.2, 0.2, 0.2, 0.2, 0.1, 0.1),\n",
        "#     top_k=10\n",
        "# )"
      ],
      "metadata": {
        "id": "full_example_code"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
